{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedc9203-b5ee-4f67-98b5-afb6966a1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import evaluation\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] =  'tcloud-ga.json'\n",
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcbf6c3-6efb-49f9-b26b-c87fa7041f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query1 =\"\"\"\n",
    "with orderinfo as(\n",
    "SELECT sme_ban, sum(sol_price) as total_pay, sum(sol_point) as pointsused , sum(sol_selfpay) as selfpay, sum(solution_duration) servicelen, count(order_num) as ordernums, solution_uuid FROM `tcloud-data-analysis.highly_use_data.orders` \n",
    "group by sme_ban,solution_uuid \n",
    "),\n",
    "sme as (\n",
    "  select * from tcloud-data-analysis.ml_data.sme_basic_numeric\n",
    "),\n",
    "page as (\n",
    "  select * from `tcloud-data-analysis.ga3.solution_pv`\n",
    "),\n",
    "ind as (\n",
    "  select sme_ban, ind_large from `tcloud-data-analysis.tcloud_analytics_iii.sme_basic`\n",
    ")\n",
    "\n",
    "select orderinfo.* , sme.* EXCEPT(sme_ban), page.* EXCEPT(clean_path2), ind_large\n",
    "from orderinfo\n",
    "join sme on orderinfo.sme_ban = sme.sme_ban\n",
    "join page on orderinfo.solution_uuid = page.clean_path2\n",
    "join ind on orderinfo.sme_ban= ind.sme_ban\n",
    "\"\"\"\n",
    "query_job1 = bq_client.query(sql_query1)\n",
    "recommend = query_job1.to_dataframe()\n",
    "\n",
    "\n",
    "query_indnm = \"\"\"\n",
    "SELECT * FROM `tcloud-data-analysis.tcloud_analytics_iii.industry_large`\n",
    "\"\"\"\n",
    "\n",
    "# 查詢資料並將結果存為 DataFrame\n",
    "query_job = bq_client.query(query_indnm)\n",
    "industry_df = query_job.to_dataframe()\n",
    "\n",
    "# 提取所有可能的 ind_large 選項\n",
    "ind_large_values = industry_df['ind_large'].unique()\n",
    "\n",
    "\n",
    "query_subcate = \"\"\"\n",
    "SELECT * FROM `tcloud-data-analysis.tcloud_analytics_iii.solution_subcategory_encoding`\n",
    "\"\"\"\n",
    "\n",
    "# 查詢資料並將結果存為 DataFrame\n",
    "query_job = bq_client.query(query_subcate)\n",
    "solution_sub = query_job.to_dataframe()\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# 將 ind_large 轉換為 CategoricalDtype 並指定所有可能的類別\n",
    "ind_large_type = CategoricalDtype(categories=ind_large_values, ordered=False)\n",
    "recommend['ind_large'] = recommend['ind_large'].astype(ind_large_type)\n",
    "\n",
    "# 進行 one-hot encoding\n",
    "ind_large_dummies = pd.get_dummies(recommend['ind_large'], prefix='ind_large')\n",
    "\n",
    "# 將所有編碼列轉換為 'Int64' 數據類型\n",
    "ind_large_dummies = ind_large_dummies.astype('Int64')\n",
    "\n",
    "# 合併原始 DataFrame 和編碼後的 DataFrame\n",
    "recommend = pd.concat([recommend.drop('ind_large', axis=1), ind_large_dummies], axis=1)\n",
    "recommend = recommend.merge(solution_sub, on='solution_uuid', how='left')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ...其他程式碼(資料讀取等)...\n",
    "\n",
    "def create_mappings(df, user_col, item_col):\n",
    "    user_mapping = {user: idx for idx, user in enumerate(df[user_col].unique())}\n",
    "    item_mapping = {item: idx for idx, item in enumerate(df[item_col].unique())}\n",
    "    return user_mapping, item_mapping\n",
    "\n",
    "def encode_data(df, user_col, item_col, user_mapping, item_mapping):\n",
    "    df[user_col] = df[user_col].map(user_mapping)\n",
    "    df[item_col] = df[item_col].map(item_mapping)\n",
    "    return df\n",
    "\n",
    "def reverse_mappings(mapping):\n",
    "    return {idx: key for key, idx in mapping.items()}\n",
    "\n",
    "def save_mappings(user_reverse_mapping, item_reverse_mapping, user_mapping_filename, item_mapping_filename):\n",
    "    user_reverse_mapping_df = pd.DataFrame(list(user_reverse_mapping.items()), columns=['encoded', 'original'])\n",
    "    item_reverse_mapping_df = pd.DataFrame(list(item_reverse_mapping.items()), columns=['encoded', 'original'])\n",
    "    user_reverse_mapping_df.to_csv(user_mapping_filename, index=False)\n",
    "    item_reverse_mapping_df.to_csv(item_mapping_filename, index=False)\n",
    "\n",
    "sme_ban_mapping, solution_uuid_mapping = create_mappings(recommend, 'sme_ban', 'solution_uuid')\n",
    "\n",
    "recommend_encoded = encode_data(recommend.copy(), 'sme_ban', 'solution_uuid', sme_ban_mapping, solution_uuid_mapping)\n",
    "\n",
    "sme_ban_reverse_mapping = reverse_mappings(sme_ban_mapping)\n",
    "solution_uuid_reverse_mapping = reverse_mappings(solution_uuid_mapping)\n",
    "\n",
    "save_mappings(sme_ban_reverse_mapping, solution_uuid_reverse_mapping, 'sme_ban_reverse_mapping.csv', 'solution_uuid_reverse_mapping.csv')\n",
    "\n",
    "recommend_encoded = recommend_encoded.dropna(axis=0)\n",
    "# 數據分割\n",
    "train_data, test_data = train_test_split(recommend_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 欄位分割\n",
    "sme_ban_columns = [\n",
    "    'q_organizationsize_level', 'q_planningtime_level', 'q_budget_level',\n",
    "    'opscore1', 'opscore2', 'marscore1', 'marscore2', 'salescore1', 'salescore2',\n",
    "    'securscore1', 'securscore2', 'remotescore1', 'remotescore2', 'schedscore1',\n",
    "    'schedscore2', 'sme_age', 'capital', 'employee_count',\n",
    "    'ind_large_A', 'ind_large_B', 'ind_large_C', 'ind_large_D',\n",
    "    'ind_large_E', 'ind_large_F', 'ind_large_G', 'ind_large_H',\n",
    "    'ind_large_I', 'ind_large_J', 'ind_large_K', 'ind_large_L',\n",
    "    'ind_large_M', 'ind_large_N', 'ind_large_P', 'ind_large_Q',\n",
    "    'ind_large_R', 'ind_large_S'\n",
    "]\n",
    "\n",
    "solution_uuid_columns = [\n",
    "    'pageview', 'bound', 'in_site', 'crm_system', 'erp_system', 'pos_integration', 'seo',\n",
    "    'hr_management', 'credit_card_ticketing', 'survey_analysis',\n",
    "    'big_data_analysis', 'customer_interaction', 'market_research',\n",
    "    'digital_advertising', 'document_processing_software',\n",
    "    'membership_point_system', 'production_logistics_management',\n",
    "    'carbon_emission_calculation_analysis',\n",
    "    'community_content_management_operation', 'sms_system',\n",
    "    'online_customer_service', 'online_meeting', 'online_reservation',\n",
    "    'energy_management_system', 'mobile_payment',\n",
    "    'marketing_matchmaking_kol', 'financial_management',\n",
    "    'information_security', 'public_opinion_analysis',\n",
    "    'inventory_management_system', 'remote_collaboration',\n",
    "    'antivirus_software', 'ecommerce_online_shopping_platform',\n",
    "    'enewsletter_edm', 'electronic_invoice'\n",
    "]\n",
    "interaction_columns = ['total_pay']\n",
    "\n",
    "# 將訓練集和測試集拆分為用戶編碼、物品編碼和交互作用\n",
    "train_sme_ban = train_data['sme_ban'].astype('int32')\n",
    "train_solution_uuid = train_data['solution_uuid'].astype('int32')\n",
    "train_interactions = train_data[interaction_columns].astype('int32')\n",
    "\n",
    "test_sme_ban = test_data['sme_ban'].astype('int32')\n",
    "test_solution_uuid = test_data['solution_uuid'].astype('int32')\n",
    "test_interactions = test_data[interaction_columns].astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "#interaction_columns = ['sme_ban', 'solution_uuid', 'total_pay', 'pointsused', 'selfpay', 'servicelen', 'ordernums']\n",
    "\n",
    "# 分別獲取訓練集和測試集中的用戶和物品特徵\n",
    "train_sme_ban_features = train_data[sme_ban_columns].astype('int32')\n",
    "train_solution_uuid_features = train_data[solution_uuid_columns].astype('int32')\n",
    "\n",
    "test_sme_ban_features = test_data[sme_ban_columns].astype('int32')\n",
    "test_solution_uuid_features = test_data[solution_uuid_columns].astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b55e43-9566-46fd-b44e-8975fc4271ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsme_id_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `tcloud-data-analysis.ml_data.new_sme` \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 查詢資料並將結果存為 DataFrame\n",
    "query_job = bq_client.query(newsme_id_query)\n",
    "newsme = query_job.to_dataframe()\n",
    "newsme_id= newsme['sme_ban'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711f32e5-67e5-47dc-8511-a103422f3f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sme_ban', 'q_organizationsize_level', 'q_planningtime_level',\n",
      "       'q_budget_level', 'opscore1', 'opscore2', 'marscore1', 'marscore2',\n",
      "       'salescore1', 'salescore2', 'securscore1', 'securscore2',\n",
      "       'remotescore1', 'remotescore2', 'schedscore1', 'schedscore2', 'sme_age',\n",
      "       'capital', 'employee_count', 'ind_large'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(newsme.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23de169-dab4-424b-924e-ea13a7089a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 ind_large 轉換為 CategoricalDtype 並指定所有可能的類別\n",
    "ind_large_type = CategoricalDtype(categories=ind_large_values, ordered=False)\n",
    "newsme['ind_large'] = newsme['ind_large'].astype(ind_large_type)\n",
    "\n",
    "# 進行 one-hot encoding\n",
    "ind_large_dummies = pd.get_dummies(newsme['ind_large'], prefix='ind_large')\n",
    "\n",
    "# 將所有編碼列轉換為 'Int64' 數據類型\n",
    "ind_large_dummies = ind_large_dummies.astype('Int64')\n",
    "\n",
    "# 合併原始 DataFrame 和編碼後的 DataFrame\n",
    "newsme = pd.concat([newsme.drop('ind_large', axis=1), ind_large_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64788daa-9ab1-445c-836f-defae1f5d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsme[sme_ban_columns]= newsme[sme_ban_columns].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6f45bb-13ce-4d18-aabd-e2182f0c862d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsme_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c69cb19-a741-4589-a213-a67d9567a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sme_ban': '81330190', 'features': {'q_organizationsize_level': 1, 'q_planningtime_level': 5, 'q_budget_level': 2, 'opscore1': 10, 'opscore2': 25, 'marscore1': 0, 'marscore2': 0, 'salescore1': 25, 'salescore2': 25, 'securscore1': 0, 'securscore2': 25, 'remotescore1': 0, 'remotescore2': 0, 'schedscore1': 25, 'schedscore2': 25, 'sme_age': 243, 'capital': 100000, 'employee_count': 0, 'ind_large_A': 0, 'ind_large_B': 0, 'ind_large_C': 0, 'ind_large_D': 0, 'ind_large_E': 0, 'ind_large_F': 0, 'ind_large_G': 0, 'ind_large_H': 0, 'ind_large_I': 1, 'ind_large_J': 0, 'ind_large_K': 0, 'ind_large_L': 0, 'ind_large_M': 0, 'ind_large_N': 0, 'ind_large_O': 0, 'ind_large_P': 0, 'ind_large_Q': 0, 'ind_large_R': 0, 'ind_large_S': 0}}\n"
     ]
    }
   ],
   "source": [
    "def row_to_dict(row):\n",
    "    data = {\"sme_ban\": row['sme_ban'],\n",
    "            \"features\": row.drop('sme_ban').to_dict()\n",
    "            }\n",
    "    return data\n",
    "\n",
    "# 將 DataFrame 的第五個 row 轉換為 dict\n",
    "fifth_row_dict = row_to_dict(newsme.iloc[500])\n",
    "print(fifth_row_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0044bbf-0b09-427a-aae1-f673728a7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsme.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72345adb-eaf6-499e-a791-ca89ad4f5cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4770ed-2e2b-4c63-83ba-70d2904703f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1fb49-49d7-4376-b2d0-7df0287ecd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b145b-aa9e-45e8-bcb5-863e9faee8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ea2af-9c71-4895-b845-2e6fd8f74574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1efce8-bafb-4fbf-b767-322a2635fed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf3db8c-e4f9-49c1-bbf5-36ce8419b414",
   "metadata": {},
   "source": [
    "開始分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4914ad27-8e36-4103-b588-4e6de255e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_d = '''\n",
    "with sme as(\n",
    "SELECT sme_ban, point_est_date \n",
    "FROM `tcloud-data-analysis.tcloud_analytics_iii.sme_basic` \n",
    "WHERE point_est_date BETWEEN DATE '2023-06-01' AND DATE '2023-06-20'\n",
    "),\n",
    "orders as(\n",
    "  select sme_ban, sum(sol_price) as total_sales, sum(sol_point) as total_points ,count(order_num) as total_order\n",
    "  from `tcloud-data-analysis.tcloud_analytics_iii.order_basic`\n",
    "  where sme_ban in (select sme_ban from sme)\n",
    "  group by sme_ban\n",
    ")\n",
    "\n",
    "select sme.sme_ban,point_est_date ,COALESCE(total_sales, 0) as total_sales, COALESCE(total_points, 0) as total_points, COALESCE(total_order, 0) as total_order from sme\n",
    "left join orders on sme.sme_ban = orders.sme_ban\n",
    "'''\n",
    "query_jobd = bq_client.query(query_d)\n",
    "abtest = query_jobd.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "841d59ed-25b2-4b0a-9425-dfc1df8681da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 Statistics:\n",
      "          total_sales  total_points  total_order\n",
      "count     442.000000    442.000000   442.000000\n",
      "mean    41256.192308  20284.721719     1.282805\n",
      "std     25653.773678  12134.340061     0.903068\n",
      "min         0.000000      0.000000     0.000000\n",
      "25%     22800.000000  11400.000000     1.000000\n",
      "50%     46800.000000  23400.000000     1.000000\n",
      "75%     60000.000000  30000.000000     2.000000\n",
      "max    157500.000000  72000.000000     6.000000\n",
      "\n",
      "Group 2 Statistics:\n",
      "          total_sales  total_points  total_order\n",
      "count     441.000000     441.00000   441.000000\n",
      "mean    40276.224490   19850.85941     1.208617\n",
      "std     27056.555643   13165.72809     1.012206\n",
      "min         0.000000       0.00000     0.000000\n",
      "25%     20000.000000   10000.00000     1.000000\n",
      "50%     42000.000000   21000.00000     1.000000\n",
      "75%     60000.000000   30000.00000     1.000000\n",
      "max    160000.000000   90000.00000    10.000000\n",
      "\n",
      "Group 3 Statistics:\n",
      "          total_sales   total_points  total_order\n",
      "count     441.000000     441.000000    441.00000\n",
      "mean    43036.258503   21059.210884      1.24263\n",
      "std     31325.029127   14913.074278      0.95470\n",
      "min         0.000000       0.000000      0.00000\n",
      "25%     22800.000000   11400.000000      1.00000\n",
      "50%     47712.000000   23856.000000      1.00000\n",
      "75%     60000.000000   30000.000000      2.00000\n",
      "max    240000.000000  120000.000000      7.00000\n"
     ]
    }
   ],
   "source": [
    "# 隨機打亂資料集\n",
    "abtest = abtest.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 分割成三份\n",
    "gp1 = abtest.iloc[:442]\n",
    "gp2 = abtest.iloc[442:883]\n",
    "gp3 = abtest.iloc[883:]\n",
    "\n",
    "# 計算各組的統計數字\n",
    "gp1_stats = gp1.describe()\n",
    "gp2_stats = gp2.describe()\n",
    "gp3_stats = gp3.describe()\n",
    "\n",
    "# 打印統計數字\n",
    "print(\"Group 1 Statistics:\\n\", gp1_stats)\n",
    "print(\"\\nGroup 2 Statistics:\\n\", gp2_stats)\n",
    "print(\"\\nGroup 3 Statistics:\\n\", gp3_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46780024-99f8-44a1-8b56-edb93ff5437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 07:31:18.500185 1895 warnings.py:110] \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "W0622 07:31:18.502290 1895 warnings.py:110] \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "W0622 07:31:18.504326 1895 warnings.py:110] \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 為每個組別新增version列並分配對應的模型名稱\n",
    "gp1['version'] = 'NCF Model'\n",
    "gp2['version'] = 'Random'\n",
    "gp3['version'] = 'NCF+SHAP'\n",
    "\n",
    "# 將三組數據合併成一個大的數據集\n",
    "recommed_ver = pd.concat([gp1, gp2, gp3], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c999cbd-b267-4018-b0f0-88925ddd5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommed_ver.to_csv('recommed_ver.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa1d3827-bc4a-4839-8e74-10bf66894e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File recommed_ver.csv uploaded to recommed_ver.csv.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# 建立儲存客戶端\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# 指定你的 bucket 名稱\n",
    "bucket_name ='model_ncf_output'\n",
    "\n",
    "# 獲取 bucket\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# 指定要上傳的文件\n",
    "source_file_name ='recommed_ver.csv'\n",
    "# 指定 GCS 上的文件名\n",
    "destination_blob_name = 'recommed_ver.csv'\n",
    "\n",
    "# 建立 blob\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "# 上傳文件\n",
    "blob.upload_from_filename(source_file_name)\n",
    "\n",
    "print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3330fdf6-1991-4729-979c-239493f2b465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sme_ban                   object\n",
       "point_est_date    datetime64[ns]\n",
       "total_sales                Int64\n",
       "total_points               Int64\n",
       "total_order                Int64\n",
       "version                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommed_ver.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70db7bd6-5739-4c3b-b878-ebaed38f25f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tcloud-data-analysis, location=asia-east1, id=a940be64-7d2c-4cf6-a676-9efb4c25c235>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將資料轉成 BigQuery 的格式\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"sme_ban\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"point_est_date\", bigquery.enums.SqlTypeNames.TIMESTAMP),\n",
    "        bigquery.SchemaField(\"total_sales\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"total_points\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"total_order\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"version\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n",
    "table_id = \"tcloud-data-analysis.ml_data.recommend_ver\"\n",
    "job = bq_client.load_table_from_dataframe(recommed_ver, table_id, job_config=job_config)\n",
    "\n",
    "# Wait for the load job to complete.\n",
    "job.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fe7db-bfdc-43ab-929e-4d759506d940",
   "metadata": {},
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e7b861-3449-4c69-9329-916e9c6e4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatapikey = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41ccee23-f7f1-4cad-baa0-9cd2630fade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! In the SHAP model, the top three positive SHAP values mean that these three features have the strongest positive impact on the predicted outcome. \n",
      "\n",
      "The first feature, total page views of the product, suggests that higher page views positively influence the outcome. This means that the more times a user views the product page, the more likely they are to have a positive outcome.\n",
      "\n",
      "The second feature, user's industry type, indicates that certain industries have a positive influence on the outcome prediction. It means that if a user belongs to a specific industry, it increases the likelihood of a positive outcome compared to other industry types.\n",
      "\n",
      "The third feature, user's company size, suggests that the size of the user's company has a positive impact on the outcome. This means that users from larger companies are more likely to achieve a positive outcome compared to users from smaller companies.\n",
      "\n",
      "Overall, these three features play a significant role in determining a positive outcome as per the SHAP model predictions.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant explaining SHAP model output in plain language.\"},\n",
    "        {\"role\": \"user\", \"content\": \"The top three positive SHAP values are total page views of the product, user's industry type, and user's company size. Can you explain what this means?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df4bd7fd-8cb9-46fb-8014-7da5359556ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP 模型的輸出結果顯示，在這個模型中，產品的總瀏覽量、用戶的行業類型和用戶的公司規模是非常重要的因素。這意味著這三個因素對於模型預測結果的影響最大。具體地說，產品的總瀏覽量、用戶的行業類型和用戶的公司規模的變化，能夠對最終的預測結果產生較大的影響。這些因素的值越高，對於模型預測結果的貢獻越大。因此，在對產品進行推薦或預測時，我們應該重視這三個因素，並根據其值來進行相應的分析和決策。\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = chatapikey\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一個助理，需要以淺顯易懂的語言來解釋 SHAP 模型的輸出結果。\"},\n",
    "        {\"role\": \"user\", \"content\": \"SHAP 值最高的三個因素分別是產品的總瀏覽量，用戶的行業類型，和用戶的公司規模，這是什麼意思？\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb469dc-b37e-4ef5-8200-610326823296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131af4df-819c-4a99-ac6a-ddfb8f442dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831fc6f-1941-4524-9e2e-e2f88ff28c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09355931-53aa-45e0-9156-5aefaedc6682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba40f66-fdff-48c4-a7ac-25165bcde898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34924860-b7b7-4a3b-ad3b-a954816646c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08a3f1-5367-41dd-baac-e5584991aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://10.140.0.35:5000/predict\"  # Update with your server's IP address and port\n",
    "\n",
    "\n",
    "response = requests.post(url, json=fifth_row_dict)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0f741-a403-485a-b694-26faa3460d1e",
   "metadata": {},
   "source": [
    "這段先不執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574617e7-6bb5-4514-959b-84de907cf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# 創建 DataFrame\n",
    "recommend_result = pd.DataFrame(columns=['sme_ban', 'top1', 'top2', 'top3', 'top4', 'top5'])\n",
    "\n",
    "url = \"http://10.140.0.35:5000/predict\"  # Update with your server's IP address and port\n",
    "\n",
    "# 對 newsme 的每一個 row 執行以下操作\n",
    "for i, row in newsme.iterrows():\n",
    "    # 轉換 row 為 dict\n",
    "    row_dict = row_to_dict(row)\n",
    "\n",
    "    # 發送請求至 API\n",
    "    response = requests.post(url, json=row_dict)\n",
    "\n",
    "    # 獲取回應中的 'top_5_item_ids'\n",
    "    top_5_item_ids = response.json()['top_5_item_ids']\n",
    "\n",
    "    # 將 'sme_ban' 和 'top_5_item_ids' 存入 DataFrame\n",
    "    recommend_result = recommend_result.append({\n",
    "        'sme_ban': row_dict['sme_ban'],\n",
    "        'top1': top_5_item_ids[0],\n",
    "        'top2': top_5_item_ids[1],\n",
    "        'top3': top_5_item_ids[2],\n",
    "        'top4': top_5_item_ids[3],\n",
    "        'top5': top_5_item_ids[4],\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# 顯示 DataFrame\n",
    "recommend_result.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92c081-26cd-47e1-bcc1-61e5ce7d8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "junebefore ='''\n",
    "SELECT sme_ban \n",
    "FROM `tcloud-data-analysis.tcloud_analytics_iii.sme_basic` \n",
    "WHERE point_est_date < '2023-06-01'\n",
    "'''\n",
    "query_jobmm = bq_client.query(junebefore)\n",
    "june_sme = query_jobmm.to_dataframe()\n",
    "june_sme_id = june_sme['sme_ban'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4dc0b-ccdd-4249-a9c6-07121d43bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有上架产品的数据\n",
    "sql_query2 = \"\"\"\n",
    "SELECT solution_uuid FROM `tcloud-data-analysis.tcloud_analytics_iii.solution_info` \n",
    "WHERE solution_status ='上架' AND solution_uuid IN (SELECT DISTINCT(solution_uuid) FROM tcloud-data-analysis.tcloud_analytics_iii.order_basic)\n",
    "\"\"\"\n",
    "\n",
    "query_job2 = bq_client.query(sql_query2)\n",
    "on_shelf_solutions = query_job2.to_dataframe()\n",
    "on_shelf_item_ids = on_shelf_solutions['solution_uuid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f240c-60c0-4919-91b3-64da7698ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 創建 DataFrame\n",
    "recommend_result = pd.DataFrame(columns=['sme_ban', 'top1', 'top2', 'top3', 'top4', 'top5'])\n",
    "\n",
    "# 對六月以前的每一個 sme_ban 執行以下操作\n",
    "for sme_ban in june_sme_id:\n",
    "    # 隨機從 on_shelf_item_ids 中選取五個不重複的元素\n",
    "    top_5_item_ids = random.sample(on_shelf_item_ids, 5)\n",
    "    \n",
    "    # 將 'sme_ban' 和 'top_5_item_ids' 存入 DataFrame\n",
    "    recommend_result = recommend_result.append({\n",
    "        'sme_ban': sme_ban,\n",
    "        'top1': top_5_item_ids[0],\n",
    "        'top2': top_5_item_ids[1],\n",
    "        'top3': top_5_item_ids[2],\n",
    "        'top4': top_5_item_ids[3],\n",
    "        'top5': top_5_item_ids[4],\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# 顯示 DataFrame\n",
    "recommend_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de7fea-ae2e-4266-acb1-41fdb6480e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "after531q ='''\n",
    "SELECT sme_ban \n",
    "FROM `tcloud-data-analysis.tcloud_analytics_iii.sme_basic` \n",
    "WHERE point_est_date > '2023-05-31'\n",
    "'''\n",
    "query_job531 = bq_client.query(after531q)\n",
    "sme_531 = query_job531.to_dataframe()\n",
    "sme_531_ids = sme_531['sme_ban'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6642e1-a6fd-4f1a-8ca1-947d584e8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 隨機打亂列表中的元素\n",
    "random.shuffle(sme_531_ids)\n",
    "\n",
    "# 計算每一部分的元素數量\n",
    "part_size = len(sme_531_ids) // 3\n",
    "\n",
    "# 切片來分配元素\n",
    "ncf_1 = sme_531_ids[:part_size]\n",
    "ncf_2 = sme_531_ids[part_size:2*part_size]\n",
    "random_1 = sme_531_ids[2*part_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffffa72-667a-416e-9339-82e3da727af5",
   "metadata": {},
   "source": [
    "random 的統編"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89941c48-0b4e-413d-aeb4-af5071a6697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 創建 DataFrame\n",
    "recommend_result_random = pd.DataFrame(columns=['sme_ban', 'top1', 'top2', 'top3', 'top4', 'top5'])\n",
    "\n",
    "# 對六月以前的每一個 sme_ban 執行以下操作\n",
    "for sme_ban in random_1:\n",
    "    # 隨機從 on_shelf_item_ids 中選取五個不重複的元素\n",
    "    top_5_item_ids = random.sample(on_shelf_item_ids, 5)\n",
    "    \n",
    "    # 將 'sme_ban' 和 'top_5_item_ids' 存入 DataFrame\n",
    "    recommend_result_random = recommend_result_random.append({\n",
    "        'sme_ban': sme_ban,\n",
    "        'top1': top_5_item_ids[0],\n",
    "        'top2': top_5_item_ids[1],\n",
    "        'top3': top_5_item_ids[2],\n",
    "        'top4': top_5_item_ids[3],\n",
    "        'top5': top_5_item_ids[4],\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# 顯示 DataFrame\n",
    "recommend_result_random.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21795c-60eb-49db-b786-158bfea75eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sme_531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507774e-66fc-426d-9a8d-f49b32844ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9efd68-1a33-46f4-8a45-891a32708566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a8758f-dfb8-406d-8a2d-ddd6f079fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import evaluation\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] =  'tcloud-ga.json'\n",
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815f5a35-0514-44d4-8ed2-c0c1e6f183b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query1 =\"\"\"\n",
    "with orderinfo as(\n",
    "SELECT sme_ban, sum(sol_price) as total_pay, sum(sol_point) as pointsused , sum(sol_selfpay) as selfpay, sum(solution_duration) servicelen, count(order_num) as ordernums, solution_uuid FROM `tcloud-data-analysis.highly_use_data.orders` \n",
    "group by sme_ban,solution_uuid \n",
    "),\n",
    "sme as (\n",
    "  select * from tcloud-data-analysis.ml_data.sme_basic_numeric\n",
    "),\n",
    "page as (\n",
    "  select * from `tcloud-data-analysis.ga3.solution_pv`\n",
    "),\n",
    "ind as (\n",
    "  select sme_ban, ind_large from `tcloud-data-analysis.tcloud_analytics_iii.sme_basic`\n",
    ")\n",
    "\n",
    "select orderinfo.* , sme.* EXCEPT(sme_ban), page.* EXCEPT(clean_path2), ind_large\n",
    "from orderinfo\n",
    "join sme on orderinfo.sme_ban = sme.sme_ban\n",
    "join page on orderinfo.solution_uuid = page.clean_path2\n",
    "join ind on orderinfo.sme_ban= ind.sme_ban\n",
    "\"\"\"\n",
    "query_job1 = bq_client.query(sql_query1)\n",
    "recommend = query_job1.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57aea3a1-3fa5-49f7-b92c-68f6d461fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_indnm = \"\"\"\n",
    "SELECT * FROM `tcloud-data-analysis.tcloud_analytics_iii.industry_large`\n",
    "\"\"\"\n",
    "\n",
    "# 查詢資料並將結果存為 DataFrame\n",
    "query_job = bq_client.query(query_indnm)\n",
    "industry_df = query_job.to_dataframe()\n",
    "\n",
    "# 提取所有可能的 ind_large 選項\n",
    "ind_large_values = industry_df['ind_large'].unique()\n",
    "\n",
    "\n",
    "query_subcate = \"\"\"\n",
    "SELECT * FROM `tcloud-data-analysis.tcloud_analytics_iii.solution_subcategory_encoding`\n",
    "\"\"\"\n",
    "\n",
    "# 查詢資料並將結果存為 DataFrame\n",
    "query_job = bq_client.query(query_subcate)\n",
    "solution_sub = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876b966f-3cbc-44e3-a8ae-53920a6f9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# 將 ind_large 轉換為 CategoricalDtype 並指定所有可能的類別\n",
    "ind_large_type = CategoricalDtype(categories=ind_large_values, ordered=False)\n",
    "recommend['ind_large'] = recommend['ind_large'].astype(ind_large_type)\n",
    "\n",
    "# 進行 one-hot encoding\n",
    "ind_large_dummies = pd.get_dummies(recommend['ind_large'], prefix='ind_large')\n",
    "\n",
    "# 將所有編碼列轉換為 'Int64' 數據類型\n",
    "ind_large_dummies = ind_large_dummies.astype('Int64')\n",
    "\n",
    "# 合併原始 DataFrame 和編碼後的 DataFrame\n",
    "recommend = pd.concat([recommend.drop('ind_large', axis=1), ind_large_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a33aed-6487-4fd2-b298-6ab3536e1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend = recommend.merge(solution_sub, on='solution_uuid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79b1068-4a55-473a-9540-0aa2913a8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ...其他程式碼(資料讀取等)...\n",
    "\n",
    "def create_mappings(df, user_col, item_col):\n",
    "    user_mapping = {user: idx for idx, user in enumerate(df[user_col].unique())}\n",
    "    item_mapping = {item: idx for idx, item in enumerate(df[item_col].unique())}\n",
    "    return user_mapping, item_mapping\n",
    "\n",
    "def encode_data(df, user_col, item_col, user_mapping, item_mapping):\n",
    "    df[user_col] = df[user_col].map(user_mapping)\n",
    "    df[item_col] = df[item_col].map(item_mapping)\n",
    "    return df\n",
    "\n",
    "def reverse_mappings(mapping):\n",
    "    return {idx: key for key, idx in mapping.items()}\n",
    "\n",
    "def save_mappings(user_reverse_mapping, item_reverse_mapping, user_mapping_filename, item_mapping_filename):\n",
    "    user_reverse_mapping_df = pd.DataFrame(list(user_reverse_mapping.items()), columns=['encoded', 'original'])\n",
    "    item_reverse_mapping_df = pd.DataFrame(list(item_reverse_mapping.items()), columns=['encoded', 'original'])\n",
    "    user_reverse_mapping_df.to_csv(user_mapping_filename, index=False)\n",
    "    item_reverse_mapping_df.to_csv(item_mapping_filename, index=False)\n",
    "\n",
    "sme_ban_mapping, solution_uuid_mapping = create_mappings(recommend, 'sme_ban', 'solution_uuid')\n",
    "\n",
    "recommend_encoded = encode_data(recommend.copy(), 'sme_ban', 'solution_uuid', sme_ban_mapping, solution_uuid_mapping)\n",
    "\n",
    "sme_ban_reverse_mapping = reverse_mappings(sme_ban_mapping)\n",
    "solution_uuid_reverse_mapping = reverse_mappings(solution_uuid_mapping)\n",
    "\n",
    "save_mappings(sme_ban_reverse_mapping, solution_uuid_reverse_mapping, 'sme_ban_reverse_mapping.csv', 'solution_uuid_reverse_mapping.csv')\n",
    "\n",
    "recommend_encoded = recommend_encoded.dropna(axis=0)\n",
    "# 數據分割\n",
    "train_data, test_data = train_test_split(recommend_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 欄位分割\n",
    "sme_ban_columns = [\n",
    "    'q_organizationsize_level', 'q_planningtime_level', 'q_budget_level',\n",
    "    'opscore1', 'opscore2', 'marscore1', 'marscore2', 'salescore1', 'salescore2',\n",
    "    'securscore1', 'securscore2', 'remotescore1', 'remotescore2', 'schedscore1',\n",
    "    'schedscore2', 'sme_age', 'capital', 'employee_count',\n",
    "    'ind_large_A', 'ind_large_B', 'ind_large_C', 'ind_large_D',\n",
    "    'ind_large_E', 'ind_large_F', 'ind_large_G', 'ind_large_H',\n",
    "    'ind_large_I', 'ind_large_J', 'ind_large_K', 'ind_large_L',\n",
    "    'ind_large_M', 'ind_large_N', 'ind_large_P', 'ind_large_Q',\n",
    "    'ind_large_R', 'ind_large_S'\n",
    "]\n",
    "\n",
    "solution_uuid_columns = [\n",
    "    'pageview', 'bound', 'in_site', 'crm_system', 'erp_system', 'pos_integration', 'seo',\n",
    "    'hr_management', 'credit_card_ticketing', 'survey_analysis',\n",
    "    'big_data_analysis', 'customer_interaction', 'market_research',\n",
    "    'digital_advertising', 'document_processing_software',\n",
    "    'membership_point_system', 'production_logistics_management',\n",
    "    'carbon_emission_calculation_analysis',\n",
    "    'community_content_management_operation', 'sms_system',\n",
    "    'online_customer_service', 'online_meeting', 'online_reservation',\n",
    "    'energy_management_system', 'mobile_payment',\n",
    "    'marketing_matchmaking_kol', 'financial_management',\n",
    "    'information_security', 'public_opinion_analysis',\n",
    "    'inventory_management_system', 'remote_collaboration',\n",
    "    'antivirus_software', 'ecommerce_online_shopping_platform',\n",
    "    'enewsletter_edm', 'electronic_invoice'\n",
    "]\n",
    "interaction_columns = ['total_pay']\n",
    "\n",
    "# 將訓練集和測試集拆分為用戶編碼、物品編碼和交互作用\n",
    "train_sme_ban = train_data['sme_ban'].astype('int32')\n",
    "train_solution_uuid = train_data['solution_uuid'].astype('int32')\n",
    "train_interactions = train_data[interaction_columns].astype('int32')\n",
    "\n",
    "test_sme_ban = test_data['sme_ban'].astype('int32')\n",
    "test_solution_uuid = test_data['solution_uuid'].astype('int32')\n",
    "test_interactions = test_data[interaction_columns].astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "#interaction_columns = ['sme_ban', 'solution_uuid', 'total_pay', 'pointsused', 'selfpay', 'servicelen', 'ordernums']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c3adab-ea5e-45ec-a516-312918474a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 分別獲取訓練集和測試集中的用戶和物品特徵\n",
    "train_sme_ban_features = train_data[sme_ban_columns].astype('int32')\n",
    "train_solution_uuid_features = train_data[solution_uuid_columns].astype('int32')\n",
    "\n",
    "test_sme_ban_features = test_data[sme_ban_columns].astype('int32')\n",
    "test_solution_uuid_features = test_data[solution_uuid_columns].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1f4906-fae6-4eef-937f-408e70c79678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 03:24:22.453330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-06-04 03:24:22.453411: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-04 03:24:22.453450: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (recommend05): /proc/driver/nvidia/version does not exist\n",
      "2023-06-04 03:24:22.453940: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0604 03:24:22.534270 9701 warnings.py:110] The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1078/1078 [==============================] - 15s 13ms/step - loss: 340288208896.0000 - val_loss: 1599348352.0000\n",
      "Epoch 2/30\n",
      "1078/1078 [==============================] - 15s 13ms/step - loss: 1849012256768.0000 - val_loss: 2746698240.0000\n",
      "Epoch 3/30\n",
      "1078/1078 [==============================] - 16s 15ms/step - loss: 2803012864.0000 - val_loss: 85773164544.0000\n",
      "Epoch 4/30\n",
      "1078/1078 [==============================] - 15s 14ms/step - loss: 327902593024.0000 - val_loss: 1421984128.0000\n",
      "Epoch 5/30\n",
      "1078/1078 [==============================] - 15s 14ms/step - loss: 147042549760.0000 - val_loss: 1327577216.0000\n",
      "Epoch 6/30\n",
      "1078/1078 [==============================] - 15s 14ms/step - loss: 19649933312.0000 - val_loss: 7323889152.0000\n",
      "Epoch 7/30\n",
      "1078/1078 [==============================] - 16s 14ms/step - loss: 2046553489408.0000 - val_loss: 1465182464.0000\n",
      "Epoch 8/30\n",
      "1078/1078 [==============================] - 15s 14ms/step - loss: 7068463616.0000 - val_loss: 1230429696.0000\n",
      "Epoch 9/30\n",
      "1078/1078 [==============================] - 16s 15ms/step - loss: 2046026496.0000 - val_loss: 1859859456.0000\n",
      "Epoch 10/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 101169700864.0000 - val_loss: 1039997599744.0000\n",
      "Epoch 11/30\n",
      "1078/1078 [==============================] - 15s 14ms/step - loss: 317273571328.0000 - val_loss: 1087799168.0000\n",
      "Epoch 12/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 4317994496.0000 - val_loss: 1040523648.0000\n",
      "Epoch 13/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 31981049856.0000 - val_loss: 5864290304.0000\n",
      "Epoch 14/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 82454142976.0000 - val_loss: 1079282688.0000\n",
      "Epoch 15/30\n",
      "1078/1078 [==============================] - 15s 14ms/step - loss: 21539268608.0000 - val_loss: 16433520640.0000\n",
      "Epoch 16/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 52994502656.0000 - val_loss: 1064094016.0000\n",
      "Epoch 17/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 20956633088.0000 - val_loss: 972599808.0000\n",
      "Epoch 18/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 33846726656.0000 - val_loss: 1100547968.0000\n",
      "Epoch 19/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 10742106112.0000 - val_loss: 1225842048.0000\n",
      "Epoch 20/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 34091282432.0000 - val_loss: 23778007040.0000\n",
      "Epoch 21/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 1731558016.0000 - val_loss: 1504852224.0000\n",
      "Epoch 22/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 6267000320.0000 - val_loss: 993598848.0000\n",
      "Epoch 23/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 102289080320.0000 - val_loss: 828797056.0000\n",
      "Epoch 24/30\n",
      "1078/1078 [==============================] - 14s 13ms/step - loss: 870828928.0000 - val_loss: 910853184.0000\n",
      "Epoch 25/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 1178234624.0000 - val_loss: 1075175808.0000\n",
      "Epoch 26/30\n",
      "1078/1078 [==============================] - 12s 12ms/step - loss: 1085943168.0000 - val_loss: 6219404800.0000\n",
      "Epoch 27/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 2194166528.0000 - val_loss: 1725387648.0000\n",
      "Epoch 28/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 24839843840.0000 - val_loss: 2502195712.0000\n",
      "Epoch 29/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 47247331328.0000 - val_loss: 1011988672.0000\n",
      "Epoch 30/30\n",
      "1078/1078 [==============================] - 13s 12ms/step - loss: 1037023552.0000 - val_loss: 939676032.0000\n",
      "Time taken: 422.9331965446472 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 超参数设置\n",
    "embedding_dim = 16\n",
    "dense_layer_sizes = (128, 64)\n",
    "learning_rate = 0.0005\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# 找到可能的最大 SME_BAN 和 Solution_UUID\n",
    "max_sme_ban = max(train_sme_ban.max(), 100000)\n",
    "max_solution_uuid = max(train_solution_uuid.max(), 10000)\n",
    "\n",
    "# SME_BAN 输入\n",
    "sme_ban_input = Input(shape=(1,), name='sme_ban_input')\n",
    "sme_ban_embedding = Embedding(input_dim=max_sme_ban + 1, output_dim=embedding_dim, mask_zero=True, name='sme_ban_embedding')(sme_ban_input)\n",
    "sme_ban_vec = Flatten()(sme_ban_embedding)\n",
    "\n",
    "sme_ban_features_input = Input(shape=(len(sme_ban_columns),), name='sme_ban_features_input')\n",
    "sme_ban_combined = Concatenate()([sme_ban_vec, sme_ban_features_input])\n",
    "\n",
    "# Solution_UUID 输入\n",
    "solution_uuid_input = Input(shape=(1,), name='solution_uuid_input')\n",
    "solution_uuid_embedding = Embedding(input_dim=max_solution_uuid + 1, output_dim=embedding_dim, mask_zero=True, name='solution_uuid_embedding')(solution_uuid_input)\n",
    "solution_uuid_vec = Flatten()(solution_uuid_embedding)\n",
    "\n",
    "solution_uuid_features_input = Input(shape=(len(solution_uuid_columns),), name='solution_uuid_features_input')\n",
    "solution_uuid_combined = Concatenate()([solution_uuid_vec, solution_uuid_features_input])\n",
    "\n",
    "# 将用户和物品组合在一起\n",
    "combined = Concatenate()([sme_ban_combined, solution_uuid_combined])\n",
    "\n",
    "# 添加全连接层\n",
    "dense = Dense(dense_layer_sizes[0], activation='relu')(combined)\n",
    "dense = Dense(dense_layer_sizes[1], activation='relu')(dense)\n",
    "\n",
    "# 输出层：预测 total_pay\n",
    "total_pay_output = Dense(1, activation='linear', name='total_pay_output')(dense)\n",
    "\n",
    "# 创建模型\n",
    "model = Model(inputs=[sme_ban_input, sme_ban_features_input, solution_uuid_input, solution_uuid_features_input], outputs=[total_pay_output])\n",
    "\n",
    "# 编译模型\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    [train_sme_ban, train_sme_ban_features, train_solution_uuid, train_solution_uuid_features],\n",
    "    train_interactions,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843b795b-638b-4225-85e4-1077c88bf0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor names: ['sme_ban_input', 'sme_ban_features_input', 'solution_uuid_input', 'solution_uuid_features_input']\n",
      "Output tensor names: ['total_pay_output/BiasAdd:0']\n"
     ]
    }
   ],
   "source": [
    "# 将 Keras 模型转换为 TensorFlow 模型\n",
    "tf_model = tf.keras.models.Model.from_config(model.get_config())\n",
    "tf_model.build(model.input_shape)\n",
    "\n",
    "# 获取输入和输出张量的名称\n",
    "input_tensor_names = []\n",
    "output_tensor_names = []\n",
    "\n",
    "for input_tensor in tf_model.inputs:\n",
    "    input_tensor_names.append(input_tensor.name)\n",
    "    \n",
    "for output_tensor in tf_model.outputs:\n",
    "    output_tensor_names.append(output_tensor.name)\n",
    "\n",
    "# 输出张量名称\n",
    "print(\"Input tensor names:\", input_tensor_names)\n",
    "print(\"Output tensor names:\", output_tensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49b6353-10e6-4a7c-9fa7-f54052b31e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example output: [[26605.37]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 從訓練集中選擇一組輸入\n",
    "example_index = 0\n",
    "example_sme_ban = np.array([train_sme_ban.iloc[example_index]])\n",
    "example_sme_ban_features = train_sme_ban_features.iloc[[example_index]]\n",
    "example_solution_uuid = np.array([train_solution_uuid.iloc[example_index]])\n",
    "example_solution_uuid_features = train_solution_uuid_features.iloc[[example_index]]\n",
    "\n",
    "# 使用模型進行預測\n",
    "example_output = model.predict([example_sme_ban, example_sme_ban_features, example_solution_uuid, example_solution_uuid_features])\n",
    "print(f\"Example output: {example_output}\")\n",
    "\n",
    "def recommend_items_for_user(user_id, model, sme_ban_features, solution_uuid_features, top_n=5):\n",
    "    # 從映射中找到用戶的編碼\n",
    "    encoded_user_id = sme_ban_mapping[user_id]\n",
    "\n",
    "    # 獲取已互動過的物品\n",
    "    interacted_items_encoded = recommend_encoded[recommend_encoded['sme_ban'] == encoded_user_id]['solution_uuid'].unique()\n",
    "    interacted_items = [solution_uuid_reverse_mapping[item] for item in interacted_items_encoded]\n",
    "\n",
    "    # 找到未互動過的物品\n",
    "    all_items = set(solution_uuid_mapping.keys())\n",
    "    not_interacted_items = list(all_items - set(interacted_items))\n",
    "\n",
    "    # 準備用於預測的輸入數據\n",
    "    user_input = np.array([encoded_user_id] * len(not_interacted_items))\n",
    "    not_interacted_items_encoded = [solution_uuid_mapping[item] for item in not_interacted_items]\n",
    "    item_input = np.array(not_interacted_items_encoded)\n",
    "    user_features_input = np.repeat(sme_ban_features.loc[encoded_user_id].values.reshape(1, -1), len(not_interacted_items), axis=0)\n",
    "    item_features_input = solution_uuid_features.loc[not_interacted_items_encoded].values\n",
    "\n",
    "    # 進行預測\n",
    "    predictions = model.predict([user_input, user_features_input, item_input, item_features_input])\n",
    "\n",
    "    # 獲取前 N 個物品的索引\n",
    "    top_n_indices = predictions[:, 0].argsort()[-top_n:][::-1]\n",
    "\n",
    "    # 獲取前 N 個物品的編碼\n",
    "    top_n_items_encoded = item_input[top_n_indices]\n",
    "\n",
    "    # 將物品編碼轉換為原始 UUID\n",
    "    top_n_items = [solution_uuid_reverse_mapping[item] for item in top_n_items_encoded]\n",
    "\n",
    "    return top_n_items\n",
    "\n",
    "def prepare_new_user_input(user_features_df, num_items):\n",
    "    # 檢查新用戶特徵是否具有正確的列順序\n",
    "    if not all(user_features_df.columns == sme_ban_columns):\n",
    "        raise ValueError(\"The columns of the new user features DataFrame must match the order of sme_ban_columns.\")\n",
    "    \n",
    "    # 為新用戶分配一個編碼（可以選擇大於所有現有編碼的最大值的數字）\n",
    "    new_user_encoded = max(sme_ban_mapping.values()) + 1\n",
    "\n",
    "    # 準備輸入數據\n",
    "    user_input = np.array([new_user_encoded] * num_items)\n",
    "    user_features_input = np.repeat(user_features_df.values.reshape(1, -1), num_items, axis=0)\n",
    "\n",
    "    return user_input, user_features_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ae94c7-4deb-4168-8187-463a10c4d09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example output: [[-5415.979]]\n"
     ]
    }
   ],
   "source": [
    "# 假設以下是新用戶的特徵\n",
    "new_user_features = pd.DataFrame([{\n",
    "    'q_organizationsize_level': 3, 'q_planningtime_level': 2, 'q_budget_level': 1,\n",
    "    'opscore1': 4, 'opscore2': 3, 'marscore1': 3, 'marscore2': 2, 'salescore1': 1, 'salescore2': 2,\n",
    "    'securscore1': 2, 'securscore2': 3, 'remotescore1': 1, 'remotescore2': 2, 'schedscore1': 2,\n",
    "    'schedscore2': 3, 'sme_age': 5, 'capital': 10000, 'employee_count': 50,\n",
    "    'ind_large_A': 0, 'ind_large_B': 1, 'ind_large_C': 0, 'ind_large_D': 0,\n",
    "    'ind_large_E': 0, 'ind_large_F': 0, 'ind_large_G': 0, 'ind_large_H': 0,\n",
    "    'ind_large_I': 0, 'ind_large_J': 0, 'ind_large_K': 0, 'ind_large_L': 0,\n",
    "    'ind_large_M': 0, 'ind_large_N': 0, 'ind_large_P': 0, 'ind_large_Q': 0,\n",
    "    'ind_large_R': 0, 'ind_large_S': 0\n",
    "}], columns=sme_ban_columns)\n",
    "# 在這裡，我們使用所有物品進行預測\n",
    "num_items = len(solution_uuid_mapping)\n",
    "\n",
    "# 調用函數，為新用戶準備輸入數據\n",
    "new_user_input, new_user_features_input = prepare_new_user_input(new_user_features, num_items)\n",
    "\n",
    "# 選擇一個物品\n",
    "example_item_index = 2\n",
    "example_solution_uuid = np.array([train_solution_uuid.iloc[example_item_index]])\n",
    "example_solution_uuid_features = train_solution_uuid_features.iloc[[example_item_index]]\n",
    "\n",
    "# 使用函數為新用戶準備輸入數據\n",
    "new_user_input, new_user_features_input = prepare_new_user_input(new_user_features, 1)\n",
    "\n",
    "# 使用模型進行預測\n",
    "example_output = model.predict([new_user_input, new_user_features_input, example_solution_uuid, example_solution_uuid_features])\n",
    "print(f\"Example output: {example_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8223e080-876c-4f6b-9e84-f7537b2c3fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the encoded on-shelf items list: 333\n"
     ]
    }
   ],
   "source": [
    "# 获取所有上架产品的数据\n",
    "sql_query2 = \"\"\"\n",
    "SELECT solution_uuid FROM `tcloud-data-analysis.tcloud_analytics_iii.solution_info` \n",
    "WHERE solution_status ='上架' AND solution_uuid IN (SELECT DISTINCT(solution_uuid) FROM tcloud-data-analysis.tcloud_analytics_iii.order_basic)\n",
    "\"\"\"\n",
    "\n",
    "query_job2 = bq_client.query(sql_query2)\n",
    "on_shelf_solutions = query_job2.to_dataframe()\n",
    "on_shelf_item_ids = on_shelf_solutions['solution_uuid'].tolist()\n",
    "# 合并 train_solution_uuid_features 和 test_solution_uuid_features\n",
    "all_solution_uuid_features = pd.concat([train_solution_uuid_features, test_solution_uuid_features], axis=0)\n",
    "\n",
    "\n",
    "# 从所有数据集中提取已上架物品的特征\n",
    "on_shelf_item_encoded = []\n",
    "on_shelf_solution_uuid_features = all_solution_uuid_features.loc[on_shelf_item_encoded]\n",
    "\n",
    "# 使用 solution_uuid_mapping 将 item id 映射回所有数据集中的编码，并忽略没有映射到的数据\n",
    "\n",
    "for item_id in on_shelf_item_ids:\n",
    "    try:\n",
    "        encoded_id = solution_uuid_mapping[item_id]\n",
    "        on_shelf_item_encoded.append(encoded_id)\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "# 从所有数据集中提取已上架物品的特征\n",
    "on_shelf_solution_uuid_features = all_solution_uuid_features.loc[on_shelf_item_encoded]\n",
    "\n",
    "# 确认映射后的列表长度\n",
    "print(f\"Length of the encoded on-shelf items list: {len(on_shelf_item_encoded)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2c7808-84eb-4426-a16f-2098bdbbb10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 21.888235330581665 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"對新用戶進行預測\"\"\"\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 预测结果的 DataFrame\n",
    "predictions = []\n",
    "\n",
    "# 对每个上架产品进行预测\n",
    "for item_encoded in on_shelf_item_encoded:\n",
    "    encoded_solution_uuid = np.array([item_encoded])\n",
    "    encoded_solution_uuid_features = on_shelf_solution_uuid_features.loc[[item_encoded]]\n",
    "\n",
    "    # 为新用户准备输入数据\n",
    "    new_user_input, new_user_features_input = prepare_new_user_input(new_user_features, 1)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    output = model.predict([new_user_input, new_user_features_input, encoded_solution_uuid, encoded_solution_uuid_features])\n",
    "\n",
    "    # 将预测结果添加到列表中\n",
    "    predictions.append({\n",
    "        'solution_uuid_encoded': item_encoded,\n",
    "        'total_pay': output[0][0]\n",
    "    })\n",
    "\n",
    "# 将预测结果列表转换为 DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 显示预测结果\n",
    "predictions_df.head(5)\n",
    "\n",
    "# 挑选 total_pay 最高的前五个 solution_uuid_encoded\n",
    "top5_encoded = predictions_df.nlargest(5, 'total_pay')['solution_uuid_encoded']\n",
    "\n",
    "# 使用 solution_uuid_reverse_mapping 将 solution_uuid_encoded 解码回原始的 item id\n",
    "top5_item_ids = [solution_uuid_reverse_mapping[encoded] for encoded in top5_encoded]\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e1afef-0a67-430c-acb5-4e3ba8486c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 23.199542999267578 seconds\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def make_prediction(item_encoded):\n",
    "    encoded_solution_uuid = np.array([item_encoded])\n",
    "    encoded_solution_uuid_features = on_shelf_solution_uuid_features.loc[[item_encoded]]\n",
    "\n",
    "    # 为新用户准备输入数据\n",
    "    new_user_input, new_user_features_input = prepare_new_user_input(new_user_features, 1)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    output = model.predict([new_user_input, new_user_features_input, encoded_solution_uuid, encoded_solution_uuid_features])\n",
    "\n",
    "    return {\n",
    "        'solution_uuid_encoded': item_encoded,\n",
    "        'total_pay': output[0][0]\n",
    "    }\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 预测结果的 DataFrame\n",
    "predictions = []\n",
    "\n",
    "# 使用线程池进行并行处理\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    predictions = list(executor.map(make_prediction, on_shelf_item_encoded))\n",
    "\n",
    "# 将预测结果列表转换为 DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 显示预测结果\n",
    "predictions_df.head(5)\n",
    "\n",
    "# 挑选 total_pay 最高的前五个 solution_uuid_encoded\n",
    "top5_encoded = predictions_df.nlargest(5, 'total_pay')['solution_uuid_encoded']\n",
    "\n",
    "# 使用 solution_uuid_reverse_mapping 将 solution_uuid_encoded 解码回原始的 item id\n",
    "top5_item_ids = [solution_uuid_reverse_mapping[encoded] for encoded in top5_encoded]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b14502-670b-43e3-8da4-de8f4d3cb81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 item ids with highest total_pay:\n",
      "F03FE16033A30DAEE0531512620AC1A1\n",
      "F39E93C29D052923E0531512620AECF8\n",
      "F03FE16038970DAEE0531512620AC1A1\n",
      "F03FE160346F0DAEE0531512620AC1A1\n",
      "F03FE16039270DAEE0531512620AC1A1\n"
     ]
    }
   ],
   "source": [
    "# 顯示原始的 item id\n",
    "print(\"Top 5 item ids with highest total_pay:\")\n",
    "for item_id in top5_item_ids:\n",
    "    print(item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce813d-d92b-4d2a-82f6-75f6269c6a75",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b9801-553a-45f1-ad9a-666791b85d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 03:41:57.763851 9701 _internal.py:224] \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.140.0.35:5000\n",
      "I0604 03:41:57.764830 9701 _internal.py:224] \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "I0604 03:42:24.104906 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 03:42:24] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 10:30:19.477707 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 10:30:19] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:53:09.561118 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:53:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:53:30.839124 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:53:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:53:52.557447 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:53:52] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:54:14.178765 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:54:14] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:54:35.936804 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:54:35] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:54:57.223931 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:54:57] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:55:18.992040 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:55:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:55:41.256578 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:55:41] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:56:03.205104 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:56:03] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:56:25.727611 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:56:25] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:56:46.828043 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:56:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:57:09.024436 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:57:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:57:30.254261 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:57:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:57:51.728192 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:57:51] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:58:13.532703 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:58:13] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:58:34.830643 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:58:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:58:56.717018 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:58:56] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:59:18.377105 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:59:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 12:59:40.324105 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 12:59:40] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:00:01.628721 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:00:01] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:02:57.983638 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:02:57] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:03:20.514647 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:03:20] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:03:42.394247 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:03:42] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:04:05.107340 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:04:05] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:04:26.897938 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:04:26] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:04:49.219304 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:04:49] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:05:11.479763 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:05:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:05:34.160335 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:05:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:05:56.563301 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:05:56] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:06:18.658710 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:06:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:06:41.687704 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:06:41] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:07:03.444916 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:07:03] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:07:25.999758 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:07:25] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:07:47.792728 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:07:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "I0604 13:08:10.324143 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 13:08:10] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    sme_ban = data['sme_ban']\n",
    "    user_features_dict = data['features']\n",
    "    \n",
    "    # Convert the features to a DataFrame\n",
    "    user_features_df = pd.DataFrame([user_features_dict], columns=sme_ban_columns)\n",
    "    \n",
    "    # Prepare the input data for the new user\n",
    "    new_user_input, new_user_features_input = prepare_new_user_input(user_features_df, 1)\n",
    "    \n",
    "    # Predict total_pay for all on-shelf items and keep the results in a list\n",
    "    predictions = []\n",
    "    for item_encoded in on_shelf_item_encoded:\n",
    "        encoded_solution_uuid = np.array([item_encoded])\n",
    "        encoded_solution_uuid_features = on_shelf_solution_uuid_features.loc[[item_encoded]]\n",
    "\n",
    "        # Use the model to make a prediction\n",
    "        output = model.predict([new_user_input, new_user_features_input, encoded_solution_uuid, encoded_solution_uuid_features])\n",
    "\n",
    "        # Add the prediction result to the list\n",
    "        predictions.append({\n",
    "            'solution_uuid_encoded': item_encoded,\n",
    "            'total_pay': output[0][0]\n",
    "        })\n",
    "\n",
    "    # Convert the prediction result list into a DataFrame\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    # Select the top 5 items with highest predicted total_pay\n",
    "    top5_encoded = predictions_df.nlargest(5, 'total_pay')['solution_uuid_encoded']\n",
    "\n",
    "    # Use the reverse mapping to decode the encoded item ids back to the original item ids\n",
    "    top5_item_ids = [solution_uuid_reverse_mapping[encoded] for encoded in top5_encoded]\n",
    "\n",
    "    return jsonify({'top_5_item_ids': top5_item_ids})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edaafce2-a806-4dfe-ba89-130e7aa3626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 03:39:59.928352 9701 _internal.py:224] \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.140.0.35:5000\n",
      "I0604 03:39:59.929326 9701 _internal.py:224] \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "I0604 03:40:15.153193 9701 _internal.py:224] 10.140.0.35 - - [04/Jun/2023 03:40:15] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    sme_ban = data['sme_ban']\n",
    "    user_features_dict = data['features']\n",
    "    \n",
    "    # Convert the features to a DataFrame\n",
    "    user_features_df = pd.DataFrame([user_features_dict], columns=sme_ban_columns)\n",
    "    \n",
    "    # Prepare the input data for the new user\n",
    "    new_user_input, new_user_features_input = prepare_new_user_input(user_features_df, 1)\n",
    "    \n",
    "    # Select an item\n",
    "    example_item_index = 2\n",
    "    example_solution_uuid = np.array([train_solution_uuid.iloc[example_item_index]])\n",
    "    example_solution_uuid_features = train_solution_uuid_features.iloc[[example_item_index]]\n",
    "\n",
    "    # Make the prediction\n",
    "    output = model.predict([new_user_input, new_user_features_input, example_solution_uuid, example_solution_uuid_features])\n",
    "    \n",
    "    return jsonify({'total_pay': output.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c5c7b-46d7-4751-ba17-9cb2e26a3d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
